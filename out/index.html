<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/data/Spiky silver wide_0193d3e1-0d01-766a-a5a3-1d963637223f.original.00_00_00_11.Still001.png"/><link rel="preload" as="image" href="/data/LoRa_00022_.png"/><link rel="preload" as="image" href="/data/Gold.png"/><link rel="preload" as="image" href="/data/7.png"/><link rel="stylesheet" href="/thereport/_next/static/css/bc5510840ff8d525.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/thereport/_next/static/chunks/webpack-c616bf0064fa2a8a.js"/><script src="/thereport/_next/static/chunks/4bd1b696-692f10ba759dfb60.js" async=""></script><script src="/thereport/_next/static/chunks/517-33587aabfc1973aa.js" async=""></script><script src="/thereport/_next/static/chunks/main-app-691daef9e1d3c10f.js" async=""></script><script src="/thereport/_next/static/chunks/app/page-1afe4fd3708707b3.js" async=""></script><title>Create Next App</title><meta name="description" content="Generated by create next app"/><link rel="icon" href="/thereport/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/thereport/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_76e8a6 __variable_600b33 antialiased"><div class="min-h-screen bg-gradient-to-b from-background to-muted/20"><div class="container max-w-7xl mx-auto px-4 py-16 space-y-24"><div class="text-center space-y-6"><h1 class="text-4xl md:text-5xl font-bold text-foreground tracking-tight">AI Necklace Image Generation Development Report</h1><p class="text-xl text-muted-foreground">Date: <!-- -->January 27, 2025</p></div><section class="relative"><div class="absolute inset-0 bg-gradient-to-r from-destructive/5 to-warning/5 rounded-3xl"></div><div class="relative bg-card/60 backdrop-blur-sm rounded-3xl shadow-lg p-8 md:p-12"><h2 class="text-3xl font-semibold mb-8">Current Limitations</h2><div class="grid md:grid-cols-2 gap-12"><div class="space-y-6"><div class="flex items-center gap-3"><span class="px-3 py-1.5 text-sm font-semibold rounded-full bg-destructive/15 text-destructive">Hardware</span><h3 class="text-xl font-medium">Hardware Limitations</h3></div><ul class="list-disc pl-6 space-y-3 text-muted-foreground text-lg"><li>RTX 4090 training is limited to 24GB VRAM</li><li>Maximum image training size is 1280px</li><li>Cannot fully utilize 4K resolution dataset</li></ul></div><div class="space-y-6"><div class="flex items-center gap-3"><span class="px-3 py-1.5 text-sm font-semibold rounded-full bg-warning/15 text-warning-foreground">Quality</span><h3 class="text-xl font-medium">Impact</h3></div><ul class="list-disc pl-6 space-y-3 text-muted-foreground text-lg"><li>Incomplete image details</li><li>AI cannot capture all fine details</li><li>AI fills in missing information:<ul class="list-circle pl-6 mt-2 space-y-2"><li>Overall shape may be similar</li><li>Details may not match the original</li></ul></li></ul></div></div></div></section><section class="relative"><div class="absolute inset-0 bg-gradient-to-r from-success/5 to-success/3 rounded-3xl"></div><div class="relative bg-card/60 backdrop-blur-sm rounded-3xl shadow-lg p-8 md:p-12"><h2 class="text-3xl font-semibold mb-8">Completed Project: Necklace Render Style</h2><div class="grid grid-cols-1 md:grid-cols-3 gap-8"><div class="space-y-6"><div class="flex items-center gap-4"><span class="w-10 h-10 rounded-xl bg-success/15 text-success flex items-center justify-center font-semibold text-lg shadow-sm">1</span><h4 class="text-xl font-medium">Start from Dataset</h4></div><div class="aspect-square rounded-2xl bg-muted/50 overflow-hidden cursor-pointer group/image relative shadow-lg transition-all duration-300 ease-out hover:shadow-xl"><div class="absolute inset-0 bg-gradient-to-t from-black/30 via-transparent to-transparent opacity-0 group-hover/image:opacity-100 transition-opacity duration-300"></div><img src="/data/Spiky silver wide_0193d3e1-0d01-766a-a5a3-1d963637223f.original.00_00_00_11.Still001.png" alt="Dataset used for training" class="w-full h-full object-contain bg-black/50 transition-transform duration-500 ease-out group-hover/image:scale-[1.02]"/><div class="absolute -bottom-full group-hover/image:bottom-0 inset-x-0 bg-gradient-to-t from-black/80 to-black/40 backdrop-blur-sm p-4 transition-all duration-300"><p class="text-white text-sm font-medium">Click to view full size</p></div></div><div class="bg-card/40 backdrop-blur-sm rounded-xl p-4"><p class="text-sm text-muted-foreground leading-relaxed">Use images with the exact angle needed to highlight the details of the necklace, without any other elements interfering</p></div></div><div class="space-y-6"><div class="flex items-center gap-4"><span class="w-10 h-10 rounded-xl bg-success/15 text-success flex items-center justify-center font-semibold text-lg shadow-sm">2</span><h4 class="text-xl font-medium">Create image with AI</h4></div><div class="aspect-square rounded-2xl bg-muted/50 overflow-hidden cursor-pointer group/image relative shadow-lg transition-all duration-300 ease-out hover:shadow-xl"><div class="absolute inset-0 bg-gradient-to-t from-black/30 via-transparent to-transparent opacity-0 group-hover/image:opacity-100 transition-opacity duration-300"></div><img src="/data/LoRa_00022_.png" alt="First image created by AI" class="w-full h-full object-contain bg-black/50 transition-transform duration-500 ease-out group-hover/image:scale-[1.02]"/><div class="absolute -bottom-full group-hover/image:bottom-0 inset-x-0 bg-gradient-to-t from-black/80 to-black/40 backdrop-blur-sm p-4 transition-all duration-300"><p class="text-white text-sm font-medium">Click to view full size</p></div></div><div class="bg-card/40 backdrop-blur-sm rounded-xl p-4"><p class="text-sm text-muted-foreground leading-relaxed">Got close structure but still lacks some important details</p></div></div><div class="space-y-6"><div class="flex items-center gap-4"><span class="w-10 h-10 rounded-xl bg-success/15 text-success flex items-center justify-center font-semibold text-lg shadow-sm">3</span><h4 class="text-xl font-medium">Adjust and Upscale</h4></div><div class="aspect-square rounded-2xl bg-muted/50 overflow-hidden cursor-pointer group/image relative shadow-lg transition-all duration-300 ease-out hover:shadow-xl"><div class="absolute inset-0 bg-gradient-to-t from-black/30 via-transparent to-transparent opacity-0 group-hover/image:opacity-100 transition-opacity duration-300"></div><img src="/data/Gold.png" alt="Final result" class="w-full h-full object-contain bg-black/50 transition-transform duration-500 ease-out group-hover/image:scale-[1.02]"/><div class="absolute -bottom-full group-hover/image:bottom-0 inset-x-0 bg-gradient-to-t from-black/80 to-black/40 backdrop-blur-sm p-4 transition-all duration-300"><p class="text-white text-sm font-medium">Click to view full size</p></div></div><div class="bg-card/40 backdrop-blur-sm rounded-xl p-4"><p class="text-sm text-muted-foreground leading-relaxed">Use magnific.ai to add details, with retouching and adjustments until you get a complete result</p></div></div></div><div class="mt-12 bg-card/40 backdrop-blur-sm rounded-2xl p-8"><div class="space-y-4"><h4 class="text-xl font-medium text-foreground flex items-center gap-2"><span class="w-2 h-2 rounded-full bg-success"></span>Dataset Limitations</h4><ul class="list-disc pl-6 space-y-3 text-muted-foreground"><li>Despite being limited to 1280px, AI can capture necklace details well because:<ul class="list-circle pl-6 mt-2 space-y-2"><li>Dataset images show only the necklace in desired angles, allowing Lora model to learn complete details</li><li>The necklace is the main element, making 1280px resolution sufficient for learning</li><li>No other elements interfere with AI learning</li></ul></li><li>Upscaling with magnific.ai works well because:<ul class="list-circle pl-6 mt-2 space-y-2"><li>Initial details are clear enough for upscaling</li><li>AI can accurately imagine missing details due to clear source data</li></ul></li><li>Easy to retouch and adjust as main structure and details are correct</li></ul></div></div></div></section><section class="relative"><div class="absolute inset-0 bg-gradient-to-r from-blue-500/5 to-blue-500/3 rounded-3xl"></div><div class="relative bg-card/60 backdrop-blur-sm rounded-3xl shadow-lg p-8 md:p-12"><h2 class="text-3xl font-semibold mb-8">Current Research: Neck Area Image Style</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-8"><div class="space-y-6"><div class="flex items-center gap-4"><span class="w-10 h-10 rounded-xl bg-blue-500/15 text-blue-600 flex items-center justify-center font-semibold text-lg shadow-sm">1</span><h4 class="text-xl font-medium">Dataset used</h4></div><div class="aspect-square rounded-2xl bg-muted/50 overflow-hidden cursor-pointer group/image relative shadow-lg transition-all duration-300 ease-out hover:shadow-xl"><div class="absolute inset-0 bg-gradient-to-t from-black/30 via-transparent to-transparent opacity-0 group-hover/image:opacity-100 transition-opacity duration-300"></div><img src="/data/7.png" alt="Necklace area image" class="w-full h-full object-contain bg-black/50 transition-transform duration-500 ease-out group-hover/image:scale-[1.02]"/><div class="absolute -bottom-full group-hover/image:bottom-0 inset-x-0 bg-gradient-to-t from-black/80 to-black/40 backdrop-blur-sm p-4 transition-all duration-300"><p class="text-white text-sm font-medium">Click to view full size</p></div></div><div class="bg-card/40 backdrop-blur-sm rounded-xl p-4"><p class="text-sm text-muted-foreground leading-relaxed">The image highlights the necklace area, making the necklace smaller in the image, affecting AI&#x27;s perception of details</p></div></div><div class="space-y-6"><div class="flex items-center gap-4"><span class="w-10 h-10 rounded-xl bg-blue-500/15 text-blue-600 flex items-center justify-center font-semibold text-lg shadow-sm">2</span><h4 class="text-xl font-medium">Experiment results</h4></div><div class="bg-card/40 backdrop-blur-sm rounded-2xl p-6"><div class="space-y-4"><p class="text-muted-foreground">Experimenting - the results obtained were:</p><ul class="list-disc pl-6 space-y-2 text-muted-foreground"><li>The necklace is larger than the actual size, but the shape of the necklace is correct when the Weight of the lora model is increased</li><li>When the Weight is lowered, the size is correct but the details are not correct at all</li></ul></div></div><div class="bg-card/40 backdrop-blur-sm rounded-xl p-4"><p class="text-sm text-muted-foreground leading-relaxed">Still need to find the balance between Weight of the model to get both size and details correct</p></div></div></div><div class="mt-12 grid md:grid-cols-2 gap-8"><div class="bg-card/40 backdrop-blur-sm rounded-2xl p-8"><div class="space-y-4"><h4 class="text-xl font-medium text-foreground flex items-center gap-2"><span class="w-2 h-2 rounded-full bg-blue-500"></span>Found Limitations</h4><ul class="list-disc pl-6 space-y-3 text-muted-foreground"><li>With 1280px training limitation for Lora model:<ul class="list-circle pl-6 mt-2 space-y-2"><li>AI captures fewer necklace details due to its smaller size in the image, compared to the Render Style project where the necklace was the main element</li><li>Cannot recognize specific diamond setting characteristics, unlike the Success Story case where details were clearly visible</li></ul></li><li>Model Weight adjustment affects quality:<ul class="list-circle pl-6 mt-2 space-y-2"><li>High Weight: Correct shape but oversized</li><li>Low Weight: Correct size but incomplete details</li></ul></li></ul></div></div><div class="bg-card/40 backdrop-blur-sm rounded-2xl p-8"><div class="space-y-4"><h4 class="text-xl font-medium text-foreground flex items-center gap-2"><span class="w-2 h-2 rounded-full bg-blue-500"></span>Possible Solutions</h4><div class="space-y-6"><div class="bg-blue-500/10 rounded-xl p-6 border border-blue-500/20 space-y-6"><div><h5 class="font-medium text-lg text-blue-700 dark:text-blue-400 mb-3">Spec &amp; Dataset Improvements</h5><ul class="list-disc pl-6 space-y-4 text-muted-foreground"><li class="space-y-2"><p>Use higher specs than RTX 4090 to support 2048px or higher resolution datasets</p><ul class="list-circle pl-6 space-y-1 text-sm"><li>Approximately $1-2 per hour for 2048px resolution training</li><li>Takes about 8 hours per model training</li></ul></li><li class="space-y-2"><p>Increase dataset from current 30 images</p><ul class="list-circle pl-6 space-y-1 text-sm"><li>Take additional photos from various angles for better AI learning</li></ul></li><li class="space-y-2"><p>Testing may require multiple runs with different configs</p><ul class="list-circle pl-6 space-y-1 text-sm"><li>Experiment with Weight and other parameters until desired results are achieved</li></ul></li></ul></div></div></div></div></div></div></div></section><section class="relative"><div class="absolute inset-0 bg-gradient-to-r from-violet-500/5 to-violet-500/3 rounded-3xl"></div><div class="relative bg-card/60 backdrop-blur-sm rounded-3xl shadow-lg p-8 md:p-12"><h2 class="text-3xl font-semibold mb-8">Current Operation Progress</h2><div class="space-y-8"><div class="bg-card/40 backdrop-blur-sm rounded-xl p-6"><h4 class="text-xl font-medium mb-4">Testing L40s on RunPod</h4><div class="space-y-4 text-muted-foreground"><p>Currently testing L40s with 48GB VRAM on RunPod.io at $1.03 per hour for higher resolution training. Starting with this cost-effective spec despite availability of higher specs such as:</p><ul class="list-disc pl-6 space-y-2"><li>H200 SXM: VRAM 143GB ($3.99 per hour)</li><li>Mi300x: VRAM 192GB ($2.49 per hour)</li><li>These specs should support 2048px or higher dataset training</li></ul><div class="bg-violet-500/10 rounded-xl p-4 border border-violet-500/20 mt-4"><p class="text-sm"><span class="font-medium">Note:</span> Starting with L40s to evaluate results and cost-effectiveness before considering higher specs</p></div><ul class="list-disc pl-6 space-y-2 mt-4"><li>Maximum resolution this spec can handle for the dataset is 1536px, not reaching the desired 2048px but hoping it&#x27;s sufficient for AI to capture actual necklace details</li><li>Training time increases slightly compared to RTX 4090 despite higher VRAM</li></ul></div></div><div class="bg-card/40 backdrop-blur-sm rounded-xl p-6"><h4 class="text-xl font-medium mb-4">Dataset Improvements</h4><div class="space-y-4 text-muted-foreground"><p>Increased dataset from 30 to 50 images to provide AI with more learning data:</p><ul class="list-disc pl-6 space-y-2"><li>Added 20 new images with various angles</li><li>Improved training data diversity</li></ul></div></div><div class="bg-card/40 backdrop-blur-sm rounded-xl p-6"><p class="text-sm text-muted-foreground leading-relaxed"><span class="font-medium text-foreground">Summary:</span> While L40s offers more VRAM than RTX 4090, it&#x27;s still limited to 1536px resolution, not meeting the desired 2048px target</p></div></div></div></section><div class="text-center"><p class="text-sm text-muted-foreground">This report is continuously updated with new findings and progress</p></div></div></div><script src="/thereport/_next/static/chunks/webpack-c616bf0064fa2a8a.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[5244,[],\"\"]\n3:I[3866,[],\"\"]\n4:I[7033,[],\"ClientPageRoot\"]\n5:I[5424,[\"974\",\"static/chunks/app/page-1afe4fd3708707b3.js\"],\"default\"]\n8:I[6213,[],\"OutletBoundary\"]\na:I[6213,[],\"MetadataBoundary\"]\nc:I[6213,[],\"ViewportBoundary\"]\ne:I[4835,[],\"\"]\n:HL[\"/thereport/_next/static/css/bc5510840ff8d525.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"KXOwZULV4PcPhUYoblVym\",\"p\":\"/thereport\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/thereport/_next/static/css/bc5510840ff8d525.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_76e8a6 __variable_600b33 antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L4\",null,{\"Component\":\"$5\",\"searchParams\":{},\"params\":{},\"promises\":[\"$@6\",\"$@7\"]}],null,[\"$\",\"$L8\",null,{\"children\":\"$L9\"}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"QONZ7YAVHBTUOqU37FBrw\",{\"children\":[[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],null]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n7:{}\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Create Next App\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/thereport/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"9:null\n"])</script></body></html>